{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quaneh/tutorials-portfolio/blob/main/NVIDIA_RAPIDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Leveraging GPU-Accelerated Computing with NVIDIA RAPIDS\n",
        "\n",
        "So, what is RAPIDS? From NVIDIA's own website, RAPIDS is \"an open-source suite of GPU-accelerated data science and AI libraries with APIs that match the most popular open-source data tools.\"\n",
        "\n",
        "In other words, RAPIDS can allow data scientists and AI engineers to drastically speed up their work, without having to drastically change their workflow.\n",
        "\n",
        "In this notebook, I'll provide a bried tutorial and carry out some benchmarking using some simple data science workflows.\n",
        "\n",
        "# Setup\n",
        "\n",
        "Google Colab allows us to use GPUs for free, and by cloning the radidsai-csp-utils repo we can simplify the instalation of RAPIDS and other associated libraries."
      ],
      "metadata": {
        "id": "jDv7srankeOl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3Pj7OYQ6Fu_",
        "outputId": "a1abb3df-4189-4d5a-d7ea-0a430bb8b819"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Mon Sep 30 15:43:25 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#cuda version 12.2\n",
        "!nvcc --version\n",
        "!nvidia-smi # GPU vibe check - If this line fails, change your runtime type to T4 GPU in the toolbar on the top left of the screen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVvoVwtP6IEe",
        "outputId": "bfae314c-fbd1-4b6a-aedd-4a614f7310aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'rapidsai-csp-utils'...\n",
            "remote: Enumerating objects: 511, done.\u001b[K\n",
            "remote: Counting objects: 100% (242/242), done.\u001b[K\n",
            "remote: Compressing objects: 100% (151/151), done.\u001b[K\n",
            "remote: Total 511 (delta 159), reused 124 (delta 91), pack-reused 269 (from 1)\u001b[K\n",
            "Receiving objects: 100% (511/511), 163.95 KiB | 818.00 KiB/s, done.\n",
            "Resolving deltas: 100% (261/261), done.\n",
            "Collecting pynvml\n",
            "  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Downloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 2.9 MB/s eta 0:00:00\n",
            "Installing collected packages: pynvml\n",
            "Successfully installed pynvml-11.5.3\n",
            "Installing RAPIDS remaining 24.4.* libraries\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Requirement already satisfied: cudf-cu12==24.4.* in /usr/local/lib/python3.10/dist-packages (24.4.1)\n",
            "Collecting cuml-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cuml-cu12/cuml_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1200.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 GB 1.1 MB/s eta 0:00:00\n",
            "Collecting cugraph-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cugraph-cu12/cugraph_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1429.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 GB 1.2 MB/s eta 0:00:00\n",
            "Collecting cuspatial-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cuspatial-cu12/cuspatial_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.8/137.8 MB 6.9 MB/s eta 0:00:00\n",
            "Collecting cuproj-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cuproj-cu12/cuproj_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (920 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 920.9/920.9 kB 38.7 MB/s eta 0:00:00\n",
            "Collecting cuxfilter-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cuxfilter-cu12/cuxfilter_cu12-24.4.1-py3-none-any.whl (83 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.5/83.5 kB 6.7 MB/s eta 0:00:00\n",
            "Collecting cucim-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/cucim-cu12/cucim_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.8/5.8 MB 68.2 MB/s eta 0:00:00\n",
            "Collecting pylibraft-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/pylibraft-cu12/pylibraft_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (823.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.0/823.0 MB 1.2 MB/s eta 0:00:00\n",
            "Collecting raft-dask-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/raft-dask-cu12/raft_dask_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (170.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 170.1/170.1 MB 5.7 MB/s eta 0:00:00\n",
            "Collecting nx-cugraph-cu12==24.4.*\n",
            "  Downloading https://pypi.nvidia.com/nx-cugraph-cu12/nx_cugraph_cu12-24.4.0-py3-none-any.whl (125 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 125.7/125.7 kB 12.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (3.10.5)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (5.5.0)\n",
            "Requirement already satisfied: cuda-python<13.0a0,>=12.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (12.2.1)\n",
            "Requirement already satisfied: cupy-cuda12x>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (12.2.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (2024.6.1)\n",
            "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (0.60.0)\n",
            "Requirement already satisfied: numpy<2.0a0,>=1.23 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (1.26.4)\n",
            "Requirement already satisfied: nvtx>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (0.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (24.1)\n",
            "Requirement already satisfied: pandas<2.2.2dev0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (2.1.4)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (3.20.3)\n",
            "Requirement already satisfied: pynvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (0.3.0)\n",
            "Requirement already satisfied: pyarrow<15.0.0a0,>=14.0.1 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (14.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (13.8.1)\n",
            "Requirement already satisfied: rmm-cu12==24.4.* in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (24.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.4.*) (4.12.2)\n",
            "Collecting dask-cuda==24.4.* (from cuml-cu12==24.4.*)\n",
            "  Downloading dask_cuda-24.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting dask-cudf-cu12==24.4.* (from cuml-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/dask-cudf-cu12/dask_cudf_cu12-24.4.1-py3-none-any.whl (48 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.9/48.9 kB 4.5 MB/s eta 0:00:00\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.4.*) (1.4.2)\n",
            "Collecting rapids-dask-dependency==24.4.* (from cuml-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/rapids-dask-dependency/rapids_dask_dependency-24.4.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.4.*) (1.13.1)\n",
            "Collecting treelite==4.1.2 (from cuml-cu12==24.4.*)\n",
            "  Downloading treelite-4.1.2-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting pylibcugraph-cu12==24.4.* (from cugraph-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/pylibcugraph-cu12/pylibcugraph_cu12-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1430.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 GB 1.5 MB/s eta 0:00:00\n",
            "Collecting ucx-py-cu12==0.37.* (from cugraph-cu12==24.4.*)\n",
            "  Downloading https://pypi.nvidia.com/ucx-py-cu12/ucx_py_cu12-0.37.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.7/7.7 MB 91.2 MB/s eta 0:00:00\n",
            "Requirement already satisfied: geopandas>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from cuspatial-cu12==24.4.*) (1.0.1)\n",
            "Requirement already satisfied: bokeh>=3.1 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.4.*) (3.4.3)\n",
            "Collecting datashader>=0.15 (from cuxfilter-cu12==24.4.*)\n",
            "  Downloading datashader-0.16.3-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: holoviews>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.4.*) (1.19.1)\n",
            "Collecting jupyter-server-proxy (from cuxfilter-cu12==24.4.*)\n",
            "  Downloading jupyter_server_proxy-4.4.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: panel>=1.0 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.4.*) (1.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from cucim-cu12==24.4.*) (8.1.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from cucim-cu12==24.4.*) (0.4)\n",
            "Collecting scikit-image<0.23.0a0,>=0.19.0 (from cucim-cu12==24.4.*)\n",
            "  Downloading scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from nx-cugraph-cu12==24.4.*) (3.3)\n",
            "Collecting pynvml<11.5,>=11.0.0 (from dask-cuda==24.4.*->cuml-cu12==24.4.*)\n",
            "  Downloading pynvml-11.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: zict>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from dask-cuda==24.4.*->cuml-cu12==24.4.*) (3.0.0)\n",
            "Collecting dask==2024.1.1 (from rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*)\n",
            "  Downloading dask-2024.1.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting distributed==2024.1.1 (from rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*)\n",
            "  Downloading distributed-2024.1.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting dask-expr==0.4.0 (from rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*)\n",
            "  Downloading dask_expr-0.4.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (2.2.1)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (8.5.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (3.1.4)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (1.0.8)\n",
            "Requirement already satisfied: psutil>=5.7.2 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (3.0.0)\n",
            "Requirement already satisfied: tornado>=6.0.4 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (6.3.3)\n",
            "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (2.2.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (4.0.3)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.4.*) (1.3.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.4.*) (10.4.0)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.4.*) (2024.9.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from cuda-python<13.0a0,>=12.0->cudf-cu12==24.4.*) (3.0.11)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x>=12.0.0->cudf-cu12==24.4.*) (0.8.2)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (3.1.0)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (1.0.0)\n",
            "Requirement already satisfied: param in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (2.1.1)\n",
            "Collecting pyct (from datashader>=0.15->cuxfilter-cu12==24.4.*)\n",
            "  Downloading pyct-0.5.0-py2.py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (2.32.3)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.4.*) (2024.9.0)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.11.0->cuspatial-cu12==24.4.*) (0.9.0)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.11.0->cuspatial-cu12==24.4.*) (3.6.1)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from geopandas>=0.11.0->cuspatial-cu12==24.4.*) (2.0.6)\n",
            "Requirement already satisfied: pyviz-comms>=2.1 in /usr/local/lib/python3.10/dist-packages (from holoviews>=1.16.0->cuxfilter-cu12==24.4.*) (3.0.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57->cudf-cu12==24.4.*) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu12==24.4.*) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu12==24.4.*) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu12==24.4.*) (2024.1)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (3.7)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (3.0.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (2.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (4.66.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.4.*) (6.1.0)\n",
            "Requirement already satisfied: imageio>=2.27 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.23.0a0,>=0.19.0->cucim-cu12==24.4.*) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.23.0a0,>=0.19.0->cucim-cu12==24.4.*) (2024.9.20)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp) (3.10)\n",
            "Requirement already satisfied: jupyter-server>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.24.0)\n",
            "Collecting simpervisor>=1.0.0 (from jupyter-server-proxy->cuxfilter-cu12==24.4.*)\n",
            "  Downloading simpervisor-1.0.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-proxy->cuxfilter-cu12==24.4.*) (5.7.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->cudf-cu12==24.4.*) (2.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (2.1.5)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (3.7.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (23.1.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (6.1.12)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (5.7.2)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (6.5.4)\n",
            "Requirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (5.10.4)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.21.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (24.0.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.18.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.8.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel>=1.0->cuxfilter-cu12==24.4.*) (0.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyogrio>=0.7.2->geopandas>=0.11.0->cuspatial-cu12==24.4.*) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.2.2dev0,>=2.0->cudf-cu12==24.4.*) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=1.0->cuxfilter-cu12==24.4.*) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel>=1.0->cuxfilter-cu12==24.4.*) (1.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->datashader>=0.15->cuxfilter-cu12==24.4.*) (3.3.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.2.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu12==24.4.*) (3.20.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (4.3.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (4.12.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (4.23.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (21.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (0.20.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.4.*) (2.22)\n",
            "Downloading dask_cuda-24.4.0-py3-none-any.whl (126 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.6/126.6 kB 6.3 MB/s eta 0:00:00\n",
            "Downloading treelite-4.1.2-py3-none-manylinux2014_x86_64.whl (810 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 810.9/810.9 kB 26.1 MB/s eta 0:00:00\n",
            "Downloading dask-2024.1.1-py3-none-any.whl (1.2 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 44.8 MB/s eta 0:00:00\n",
            "Downloading dask_expr-0.4.0-py3-none-any.whl (161 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 161.7/161.7 kB 13.8 MB/s eta 0:00:00\n",
            "Downloading distributed-2024.1.1-py3-none-any.whl (1.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 46.2 MB/s eta 0:00:00\n",
            "Downloading datashader-0.16.3-py2.py3-none-any.whl (18.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.3/18.3 MB 62.9 MB/s eta 0:00:00\n",
            "Downloading scikit_image-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.7/14.7 MB 56.3 MB/s eta 0:00:00\n",
            "Downloading jupyter_server_proxy-4.4.0-py3-none-any.whl (37 kB)\n",
            "Downloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.0/47.0 kB 3.4 MB/s eta 0:00:00\n",
            "Downloading simpervisor-1.0.0-py3-none-any.whl (8.3 kB)\n",
            "Downloading pyct-0.5.0-py2.py3-none-any.whl (15 kB)\n",
            "Installing collected packages: simpervisor, pynvml, pyct, ucx-py-cu12, treelite, scikit-image, dask, pylibraft-cu12, distributed, dask-expr, cuproj-cu12, cucim-cu12, rapids-dask-dependency, pylibcugraph-cu12, datashader, cuspatial-cu12, nx-cugraph-cu12, dask-cudf-cu12, dask-cuda, raft-dask-cu12, cuml-cu12, cugraph-cu12, jupyter-server-proxy, cuxfilter-cu12\n",
            "  Attempting uninstall: pynvml\n",
            "    Found existing installation: pynvml 11.5.3\n",
            "    Uninstalling pynvml-11.5.3:\n",
            "      Successfully uninstalled pynvml-11.5.3\n",
            "  Attempting uninstall: scikit-image\n",
            "    Found existing installation: scikit-image 0.24.0\n",
            "    Uninstalling scikit-image-0.24.0:\n",
            "      Successfully uninstalled scikit-image-0.24.0\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2024.8.0\n",
            "    Uninstalling dask-2024.8.0:\n",
            "      Successfully uninstalled dask-2024.8.0\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 2024.8.0\n",
            "    Uninstalling distributed-2024.8.0:\n",
            "      Successfully uninstalled distributed-2024.8.0\n",
            "Successfully installed cucim-cu12-24.4.0 cugraph-cu12-24.4.0 cuml-cu12-24.4.0 cuproj-cu12-24.4.0 cuspatial-cu12-24.4.0 cuxfilter-cu12-24.4.1 dask-2024.1.1 dask-cuda-24.4.0 dask-cudf-cu12-24.4.1 dask-expr-0.4.0 datashader-0.16.3 distributed-2024.1.1 jupyter-server-proxy-4.4.0 nx-cugraph-cu12-24.4.0 pyct-0.5.0 pylibcugraph-cu12-24.4.0 pylibraft-cu12-24.4.0 pynvml-11.4.1 raft-dask-cu12-24.4.0 rapids-dask-dependency-24.4.1 scikit-image-0.22.0 simpervisor-1.0.0 treelite-4.1.2 ucx-py-cu12-0.37.0\n",
            "\n",
            "        ***********************************************************************\n",
            "        The pip install of RAPIDS is complete.\n",
            "        \n",
            "        Please do not run any further installation from the conda based installation methods, as they may cause issues!\n",
            "        \n",
            "        Please ensure that you're pulling from the git repo to remain updated with the latest working install scripts.\n",
            "\n",
            "        Troubleshooting:\n",
            "            - If there is an installation failure, please check back on RAPIDSAI owned templates/notebooks to see how to update your personal files. \n",
            "            - If an installation failure persists when using the latest script, please make an issue on https://github.com/rapidsai-community/rapidsai-csp-utils\n",
            "        ***********************************************************************\n",
            "        \n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/pip-install.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries and Setting Up our Dataset\n",
        "\n",
        "We'll kick this off by importing libraries and creating a synthetic dataset.\n",
        "* cudf is equivalent to pandas\n",
        "* cuml is equivalent to Scikit-Learn\n",
        "* cupy is equivalent to numpy\n",
        "\n",
        "We'll use Scikit-learn to create our data, and initialise our cuDF dataframe by converting the pandas dataframe. <br/> We've created a dataset for a classification problem, and we'll also split the data into train and test sets at this point."
      ],
      "metadata": {
        "id": "L7TkWGoymhEs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lonCAc1C5gml",
        "outputId": "e78dd13b-58ad-486a-a932-88895bb59c03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "CUDA version: 12020\n",
            "Number of GPU devices: 1\n"
          ]
        }
      ],
      "source": [
        "import cudf\n",
        "import cuml\n",
        "import cupy as cp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from cuml.preprocessing import StandardScaler as cuStandardScaler\n",
        "\n",
        "\n",
        "# Final checks that everything is ok with our GPU\n",
        "print(f\"CUDA available: {cp.cuda.is_available()}\")\n",
        "print(f\"CUDA version: {cp.cuda.runtime.runtimeGetVersion()}\")\n",
        "print(f\"Number of GPU devices: {cp.cuda.runtime.getDeviceCount()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMoxRhiu5mkV",
        "outputId": "3bc2586d-cb75-4368-ce0d-bd857a6f35c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU DataFrame shape: (1000000, 101)\n",
            "GPU DataFrame shape: (1000000, 101)\n",
            "Training set shape: (800000, 100)\n",
            "Test set shape: (200000, 100)\n"
          ]
        }
      ],
      "source": [
        "# Generate a large synthetic dataset\n",
        "n_samples = 1_000_000\n",
        "n_features = 100\n",
        "n_classes = 2\n",
        "\n",
        "X, y = make_classification(n_samples=n_samples, n_features=n_features, n_classes=n_classes, random_state=42)\n",
        "\n",
        "# Create pandas DataFrame\n",
        "df_cpu = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(n_features)])\n",
        "df_cpu['target'] = y\n",
        "\n",
        "# Create cuDF DataFrame\n",
        "df_gpu = cudf.DataFrame(df_cpu)\n",
        "\n",
        "print(f\"CPU DataFrame shape: {df_cpu.shape}\")\n",
        "print(f\"GPU DataFrame shape: {df_gpu.shape}\")\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train_cpu, X_test_cpu, y_train_cpu, y_test_cpu = train_test_split(\n",
        "    df_cpu.drop('target', axis=1), df_cpu['target'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X_train_gpu, X_test_gpu, y_train_gpu, y_test_gpu = train_test_split(\n",
        "    df_gpu.drop('target', axis=1), df_gpu['target'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training set shape: {X_train_cpu.shape}\")\n",
        "print(f\"Test set shape: {X_test_cpu.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First Benchmarking\n",
        "\n",
        "We'll do some intial pre-processing of our datasets to get an initial idea of the kind of performance benefits we can expect with RAPIDS.\n",
        "\n",
        "Here's what we'll do in our pre-preprocessing:\n",
        "We'll artificially create some missing values, as these often exist in real\n",
        "\n",
        "1.   We'll artificially create some missing values, and handle these missing values by imputing the mean value for this feature.\n",
        "2.   We'll add a categorical feature, and then encode this feature using one-hot encoding.\n",
        "3.   We will add some iteractino features.\n",
        "4.   We'll scale our numerical features to ensure that certain features don't dominate the dataset and hide the importance of others.\n"
      ],
      "metadata": {
        "id": "o-e_HgtMot6P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3_BaOU861Rc",
        "outputId": "ea354c5d-6a94-4272-e6e8-883c30a0516d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU preprocessing time: 31.57 seconds\n",
            "GPU preprocessing time: 1.44 seconds\n",
            "Speedup factor: 21.90x\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from cuml.preprocessing import StandardScaler as cuStandardScaler\n",
        "import time\n",
        "\n",
        "def preprocess_data_cpu(df):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Add some missing values\n",
        "    df.loc[np.random.choice(df.index, 100000), 'feature_0'] = np.nan\n",
        "\n",
        "    # Handle missing values\n",
        "    df['feature_0'].fillna(df['feature_0'].mean(), inplace=True)\n",
        "\n",
        "    # Create a categorical feature\n",
        "    df['cat_feature'] = pd.qcut(df['feature_1'], q=5, labels=['A', 'B', 'C', 'D', 'E'])\n",
        "\n",
        "    # Encode categorical variable\n",
        "    df = pd.get_dummies(df, columns=['cat_feature'], dtype=float)\n",
        "\n",
        "    # Create interaction features\n",
        "    df['interaction_1'] = df['feature_2'] * df['feature_3']\n",
        "    df['interaction_2'] = df['feature_4'] + df['feature_5']\n",
        "\n",
        "    # Scale numerical features\n",
        "    scaler = StandardScaler()\n",
        "    numerical_columns = [f'feature_{i}' for i in range(100)]  # Original numerical feature columns\n",
        "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n",
        "    end_time = time.time()\n",
        "    return df, end_time - start_time\n",
        "\n",
        "def preprocess_data_gpu(df):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Add some missing values\n",
        "    df['feature_0'] = df['feature_0'].mask(cudf.Series(cp.random.choice([True, False], len(df), p=[0.1, 0.9])))\n",
        "\n",
        "    # Handle missing values\n",
        "    df['feature_0'] = df['feature_0'].fillna(df['feature_0'].mean())\n",
        "\n",
        "    # Create a categorical feature\n",
        "    df['cat_feature'] = cudf.cut(df['feature_1'], bins=5, labels=['A', 'B', 'C', 'D', 'E'])\n",
        "\n",
        "    # Encode categorical variable\n",
        "    df = cudf.get_dummies(df, columns=['cat_feature'], dtype=float)\n",
        "\n",
        "    # Create interaction features\n",
        "    df['interaction_1'] = df['feature_2'] * df['feature_3']\n",
        "    df['interaction_2'] = df['feature_4'] + df['feature_5']\n",
        "\n",
        "    # Scale numerical features\n",
        "    scaler = cuStandardScaler()\n",
        "    numerical_columns = [f'feature_{i}' for i in range(100)]  # Original numerical feature columns\n",
        "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n",
        "    end_time = time.time()\n",
        "    return df, end_time - start_time\n",
        "\n",
        "# Preprocess data on CPU\n",
        "df_cpu_preprocessed, cpu_time = preprocess_data_cpu(df_cpu.copy())\n",
        "print(f\"CPU preprocessing time: {cpu_time:.2f} seconds\")\n",
        "\n",
        "# Preprocess data on GPU\n",
        "df_gpu_preprocessed, gpu_time = preprocess_data_gpu(df_gpu.copy())\n",
        "print(f\"GPU preprocessing time: {gpu_time:.2f} seconds\")\n",
        "\n",
        "speedup = cpu_time / gpu_time\n",
        "print(f\"Speedup factor: {speedup:.2f}x\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even with relatively simple operations, our speed-up is still significant. RAPIDS is over 10x faster!!\n",
        "\n",
        "NOTE:\n",
        "Did you notice our first GOTCHA when using RAPIDS?\n",
        "The cuDF library does map 1-1 with pandas. When creating the categorical feature, we can see that RAPIDS does not have a qcut function. Instead, it used the cut function, which takes slightly different input params. Watch out and don't get caught out by this small difference like I did!\n"
      ],
      "metadata": {
        "id": "OEEoPMT-qg0J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "Gw4UX_GIiK8r",
        "outputId": "ac95f121-56c1-432e-cd47-ac39308625dc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df_cpu_preprocessed' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-163985f58313>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Verify results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcpu_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_cpu_preprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgpu_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_gpu_preprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"CPU sum: {cpu_sum:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"GPU sum: {gpu_sum:.2f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df_cpu_preprocessed' is not defined"
          ]
        }
      ],
      "source": [
        "# Verify results\n",
        "cpu_sum = df_cpu_preprocessed.sum().sum()\n",
        "gpu_sum = df_gpu_preprocessed.sum().sum()\n",
        "print(f\"CPU sum: {cpu_sum:.2f}\")\n",
        "print(f\"GPU sum: {gpu_sum:.2f}\")\n",
        "print(f\"Relative difference: {abs(cpu_sum - gpu_sum) / cpu_sum:.2e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6Kowmccf8Mh3",
        "outputId": "2c2b1f49-b44f-4697-d56c-d50caa12638a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU Training time: 1271.22 seconds\n",
            "CPU Inference time: 1.18 seconds\n",
            "CPU Accuracy: 0.9753\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/cuml/internals/api_decorators.py:344: UserWarning: For reproducible results in Random Forest Classifier or for almost reproducible results in Random Forest Regressor, n_streams=1 is recommended. If n_streams is > 1, results may vary due to stream/thread timing differences, even when random_state is set\n",
            "  return func(**kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/cuml/internals/api_decorators.py:188: UserWarning: To use pickling first train using float32 data to fit the estimator\n",
            "  ret = func(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "GPU Training time: 6.84 seconds\n",
            "GPU Inference time: 0.07 seconds\n",
            "GPU Accuracy: 0.9714\n",
            "\n",
            "Training speedup factor: 185.91x\n",
            "Inference speedup factor: 17.83x\n",
            "Accuracy difference (GPU - CPU): -0.0040\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from cuml.ensemble import RandomForestClassifier as cuRandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "def train_evaluate_rf_cpu(X_train, y_train, X_test, y_test):\n",
        "    rf_cpu = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "\n",
        "    start_time = time.time()\n",
        "    rf_cpu.fit(X_train, y_train)\n",
        "    train_time = time.time() - start_time\n",
        "\n",
        "    start_time = time.time()\n",
        "    y_pred = rf_cpu.predict(X_test)\n",
        "    inference_time = time.time() - start_time\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return train_time, inference_time, accuracy\n",
        "\n",
        "def train_evaluate_rf_gpu(X_train, y_train, X_test, y_test):\n",
        "    rf_gpu = cuRandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "\n",
        "    start_time = time.time()\n",
        "    rf_gpu.fit(X_train, y_train)\n",
        "    train_time = time.time() - start_time\n",
        "\n",
        "    start_time = time.time()\n",
        "    y_pred = rf_gpu.predict(X_test)\n",
        "    inference_time = time.time() - start_time\n",
        "\n",
        "    accuracy = accuracy_score(y_test.to_numpy(), y_pred.to_numpy())\n",
        "\n",
        "    return train_time, inference_time, accuracy\n",
        "\n",
        "# CPU Random Forest\n",
        "cpu_train_time, cpu_inference_time, cpu_accuracy = train_evaluate_rf_cpu(\n",
        "    X_train_cpu, y_train_cpu, X_test_cpu, y_test_cpu\n",
        ")\n",
        "\n",
        "print(f\"CPU Training time: {cpu_train_time:.2f} seconds\")\n",
        "print(f\"CPU Inference time: {cpu_inference_time:.2f} seconds\")\n",
        "print(f\"CPU Accuracy: {cpu_accuracy:.4f}\")\n",
        "\n",
        "# GPU Random Forest\n",
        "gpu_train_time, gpu_inference_time, gpu_accuracy = train_evaluate_rf_gpu(\n",
        "    X_train_gpu, y_train_gpu, X_test_gpu, y_test_gpu\n",
        ")\n",
        "\n",
        "print(f\"\\nGPU Training time: {gpu_train_time:.2f} seconds\")\n",
        "print(f\"GPU Inference time: {gpu_inference_time:.2f} seconds\")\n",
        "print(f\"GPU Accuracy: {gpu_accuracy:.4f}\")\n",
        "\n",
        "print(f\"\\nTraining speedup factor: {cpu_train_time / gpu_train_time:.2f}x\")\n",
        "print(f\"Inference speedup factor: {cpu_inference_time / gpu_inference_time:.2f}x\")\n",
        "print(f\"Accuracy difference (GPU - CPU): {gpu_accuracy - cpu_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZjZiOKl8PZ8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import time\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU available:\", tf.test.is_built_with_cuda())\n",
        "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(100,)),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def train_evaluate_nn(X_train, y_train, X_test, y_test, device):\n",
        "    with tf.device(device):\n",
        "        model = create_model()\n",
        "\n",
        "        start_time = time.time()\n",
        "        history = model.fit(X_train, y_train, epochs=10, batch_size=1024, validation_split=0.2, verbose=0)\n",
        "        train_time = time.time() - start_time\n",
        "\n",
        "        start_time = time.time()\n",
        "        loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "        inference_time = time.time() - start_time\n",
        "\n",
        "    return train_time, inference_time, accuracy, history\n",
        "\n",
        "# Train on CPU\n",
        "cpu_train_time, cpu_inference_time, cpu_accuracy, cpu_history = train_evaluate_nn(\n",
        "    X_train_cpu.values, y_train_cpu.values, X_test_cpu.values, y_test_cpu.values, '/CPU:0'\n",
        ")\n",
        "\n",
        "print(f\"CPU Training time: {cpu_train_time:.2f} seconds\")\n",
        "print(f\"CPU Inference time: {cpu_inference_time:.2f} seconds\")\n",
        "print(f\"CPU Accuracy: {cpu_accuracy:.4f}\")\n",
        "\n",
        "# Train on GPU\n",
        "gpu_train_time, gpu_inference_time, gpu_accuracy, gpu_history = train_evaluate_nn(\n",
        "    X_train_gpu.values.get(), y_train_gpu.values.get(), X_test_gpu.values.get(), y_test_gpu.values.get(), '/GPU:0'\n",
        ")\n",
        "\n",
        "print(f\"\\nGPU Training time: {gpu_train_time:.2f} seconds\")\n",
        "print(f\"GPU Inference time: {gpu_inference_time:.2f} seconds\")\n",
        "print(f\"GPU Accuracy: {gpu_accuracy:.4f}\")\n",
        "\n",
        "print(f\"\\nTraining speedup factor: {cpu_train_time / gpu_train_time:.2f}x\")\n",
        "print(f\"Inference speedup factor: {cpu_inference_time / gpu_inference_time:.2f}x\")\n",
        "print(f\"Accuracy difference (GPU - CPU): {gpu_accuracy - cpu_accuracy:.4f}\")\n",
        "\n",
        "# Plot training history\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(cpu_history.history['accuracy'], label='CPU Training')\n",
        "plt.plot(cpu_history.history['val_accuracy'], label='CPU Validation')\n",
        "plt.plot(gpu_history.history['accuracy'], label='GPU Training')\n",
        "plt.plot(gpu_history.history['val_accuracy'], label='GPU Validation')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(cpu_history.history['loss'], label='CPU Training')\n",
        "plt.plot(cpu_history.history['val_loss'], label='CPU Validation')\n",
        "plt.plot(gpu_history.history['loss'], label='GPU Training')\n",
        "plt.plot(gpu_history.history['val_loss'], label='GPU Validation')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOIQZwdkJQ3crTjXjbs9Bgu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}