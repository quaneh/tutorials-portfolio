{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quaneh/tutorials-portfolio/blob/main/NVIDIA_RAPIDS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is RAPIDS?\n",
        "\n",
        "So, what is RAPIDS? From NVIDIA's own website, RAPIDS is:\n",
        "\n",
        "> **\"an open-source suite of GPU-accelerated data science and AI libraries with APIs that match the most popular open-source data tools.\"**\n",
        "\n",
        "In other words, RAPIDS allows data scientists and AI engineers to **drastically speed up their work** without having to completely change their workflow. 🚀\n",
        "\n",
        "In this notebook, I’ll provide a **brief tutorial** and carry out some **benchmarking** using simple data science workflows. Let’s dive in! 📊\n",
        "\n",
        "\n",
        "# Setup\n",
        "\n",
        "Google Colab allows us to use **GPUs for free**, which is fantastic for our data science projects! 💻✨\n",
        "\n",
        "To simplify the installation of **RAPIDS** and other associated libraries, we can clone the **radidsai-csp-utils** repository. This will make getting everything set up a breeze! 🚀\n"
      ],
      "metadata": {
        "id": "jDv7srankeOl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3Pj7OYQ6Fu_",
        "outputId": "1c98dbcf-6abd-4ce1-b7f3-c1f24e62698a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n",
            "Thu Oct 24 13:33:15 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "#cuda version 12.2\n",
        "!nvcc --version\n",
        "!nvidia-smi # GPU vibe check - If this line fails, change your runtime type to T4 GPU in the toolbar on the top left of the screen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVvoVwtP6IEe",
        "outputId": "c504c102-51b7-472b-eafa-e4dbe74e90c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'rapidsai-csp-utils'...\n",
            "remote: Enumerating objects: 535, done.\u001b[K\n",
            "remote: Counting objects: 100% (266/266), done.\u001b[K\n",
            "remote: Compressing objects: 100% (172/172), done.\u001b[K\n",
            "remote: Total 535 (delta 174), reused 129 (delta 94), pack-reused 269 (from 1)\u001b[K\n",
            "Receiving objects: 100% (535/535), 172.39 KiB | 602.00 KiB/s, done.\n",
            "Resolving deltas: 100% (276/276), done.\n",
            "Collecting pynvml\n",
            "  Downloading pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Downloading pynvml-11.5.3-py3-none-any.whl (53 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 2.7 MB/s eta 0:00:00\n",
            "Installing collected packages: pynvml\n",
            "Successfully installed pynvml-11.5.3\n",
            "Installing RAPIDS remaining 24.10.* libraries\n",
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Requirement already satisfied: cudf-cu12==24.10.* in /usr/local/lib/python3.10/dist-packages (24.10.1)\n",
            "Collecting cuml-cu12==24.10.*\n",
            "  Downloading https://pypi.nvidia.com/cuml-cu12/cuml_cu12-24.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (567.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 567.7/567.7 MB 2.7 MB/s eta 0:00:00\n",
            "Collecting cugraph-cu12==24.10.*\n",
            "  Downloading https://pypi.nvidia.com/cugraph-cu12/cugraph_cu12-24.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (1315.2 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 GB 1.2 MB/s eta 0:00:00\n",
            "Collecting cuspatial-cu12==24.10.*\n",
            "  Downloading https://pypi.nvidia.com/cuspatial-cu12/cuspatial_cu12-24.10.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (4.3 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.3/4.3 MB 76.0 MB/s eta 0:00:00\n",
            "Collecting cuproj-cu12==24.10.*\n",
            "  Downloading https://pypi.nvidia.com/cuproj-cu12/cuproj_cu12-24.10.0-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (915 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 915.5/915.5 kB 40.1 MB/s eta 0:00:00\n",
            "Collecting cuxfilter-cu12==24.10.*\n",
            "  Downloading https://pypi.nvidia.com/cuxfilter-cu12/cuxfilter_cu12-24.10.0-py3-none-any.whl (83 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.6/83.6 kB 7.4 MB/s eta 0:00:00\n",
            "Collecting cucim-cu12==24.10.*\n",
            "  Downloading https://pypi.nvidia.com/cucim-cu12/cucim_cu12-24.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 98.3 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pylibraft-cu12==24.10.* in /usr/local/lib/python3.10/dist-packages (24.10.0)\n",
            "Collecting raft-dask-cu12==24.10.*\n",
            "  Downloading https://pypi.nvidia.com/raft-dask-cu12/raft_dask_cu12-24.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (196.9 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 196.9/196.9 MB 5.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: nx-cugraph-cu12==24.10.* in /usr/local/lib/python3.10/dist-packages (24.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (3.10.10)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (5.5.0)\n",
            "Requirement already satisfied: cuda-python<13.0a0,>=12.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (12.2.1)\n",
            "Requirement already satisfied: cupy-cuda12x>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (12.2.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (2024.6.1)\n",
            "Requirement already satisfied: libcudf-cu12==24.10.* in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (24.10.1)\n",
            "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (0.60.0)\n",
            "Requirement already satisfied: numpy<3.0a0,>=1.23 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (1.26.4)\n",
            "Requirement already satisfied: nvtx>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (0.2.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (24.1)\n",
            "Requirement already satisfied: pandas<2.2.3dev0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<18.0.0a0,>=14.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (16.1.0)\n",
            "Requirement already satisfied: pylibcudf-cu12==24.10.* in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (24.10.1)\n",
            "Requirement already satisfied: pynvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (0.3.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (13.9.2)\n",
            "Requirement already satisfied: rmm-cu12==24.10.* in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (24.10.0)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu12==24.10.*) (4.12.2)\n",
            "Collecting cuvs-cu12==24.10.* (from cuml-cu12==24.10.*)\n",
            "  Downloading https://pypi.nvidia.com/cuvs-cu12/cuvs_cu12-24.10.0-cp310-cp310-manylinux_2_28_x86_64.whl (836.6 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 836.6/836.6 MB 1.8 MB/s eta 0:00:00\n",
            "Collecting dask-cuda==24.10.* (from cuml-cu12==24.10.*)\n",
            "  Downloading https://pypi.nvidia.com/dask-cuda/dask_cuda-24.10.0-py3-none-any.whl (133 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.2/133.2 kB 10.8 MB/s eta 0:00:00\n",
            "Collecting dask-cudf-cu12==24.10.* (from cuml-cu12==24.10.*)\n",
            "  Downloading https://pypi.nvidia.com/dask-cudf-cu12/dask_cudf_cu12-24.10.1-py3-none-any.whl (56 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.3/56.3 kB 4.9 MB/s eta 0:00:00\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.10.*) (1.4.2)\n",
            "Requirement already satisfied: nvidia-cublas-cu12 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.10.*) (12.6.3.3)\n",
            "Requirement already satisfied: nvidia-cufft-cu12 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.10.*) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.10.*) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.10.*) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.10.*) (12.5.4.2)\n",
            "Collecting rapids-dask-dependency==24.10.* (from cuml-cu12==24.10.*)\n",
            "  Downloading https://pypi.nvidia.com/rapids-dask-dependency/rapids_dask_dependency-24.10.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from cuml-cu12==24.10.*) (1.13.1)\n",
            "Collecting treelite==4.3.0 (from cuml-cu12==24.10.*)\n",
            "  Downloading treelite-4.3.0-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: pylibcugraph-cu12==24.10.* in /usr/local/lib/python3.10/dist-packages (from cugraph-cu12==24.10.*) (24.10.0)\n",
            "Collecting ucx-py-cu12==0.40.* (from cugraph-cu12==24.10.*)\n",
            "  Downloading https://pypi.nvidia.com/ucx-py-cu12/ucx_py_cu12-0.40.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (2.1 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 63.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: geopandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from cuspatial-cu12==24.10.*) (1.0.1)\n",
            "Collecting libcuspatial-cu12==24.10.* (from cuspatial-cu12==24.10.*)\n",
            "  Downloading https://pypi.nvidia.com/libcuspatial-cu12/libcuspatial_cu12-24.10.0-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (17.7 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.7/17.7 MB 87.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: bokeh>=3.1 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.10.*) (3.4.3)\n",
            "Collecting datashader>=0.15 (from cuxfilter-cu12==24.10.*)\n",
            "  Downloading datashader-0.16.3-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: holoviews>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.10.*) (1.19.1)\n",
            "Collecting jupyter-server-proxy (from cuxfilter-cu12==24.10.*)\n",
            "  Downloading jupyter_server_proxy-4.4.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: panel>=1.0 in /usr/local/lib/python3.10/dist-packages (from cuxfilter-cu12==24.10.*) (1.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from cucim-cu12==24.10.*) (8.1.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from cucim-cu12==24.10.*) (0.4)\n",
            "Requirement already satisfied: scikit-image<0.25.0a0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from cucim-cu12==24.10.*) (0.24.0)\n",
            "Collecting distributed-ucxx-cu12==0.40.* (from raft-dask-cu12==24.10.*)\n",
            "  Downloading https://pypi.nvidia.com/distributed-ucxx-cu12/distributed_ucxx_cu12-0.40.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from nx-cugraph-cu12==24.10.*) (3.4.2)\n",
            "Collecting pynvml<11.5,>=11.0.0 (from dask-cuda==24.10.*->cuml-cu12==24.10.*)\n",
            "  Downloading pynvml-11.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting zict>=2.0.0 (from dask-cuda==24.10.*->cuml-cu12==24.10.*)\n",
            "  Downloading zict-3.0.0-py2.py3-none-any.whl.metadata (899 bytes)\n",
            "Collecting ucxx-cu12==0.40.* (from distributed-ucxx-cu12==0.40.*->raft-dask-cu12==24.10.*)\n",
            "  Downloading https://pypi.nvidia.com/ucxx-cu12/ucxx_cu12-0.40.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (722 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 722.7/722.7 kB 47.1 MB/s eta 0:00:00\n",
            "Collecting dask==2024.9.0 (from rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*)\n",
            "  Downloading dask-2024.9.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting distributed==2024.9.0 (from rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*)\n",
            "  Downloading distributed-2024.9.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting dask-expr==1.1.14 (from rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*)\n",
            "  Downloading dask_expr-1.1.14-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting libucx-cu12<1.18,>=1.15.0 (from ucx-py-cu12==0.40.*->cugraph-cu12==24.10.*)\n",
            "  Downloading libucx_cu12-1.17.0-py3-none-manylinux_2_28_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (3.1.0)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (8.5.0)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (3.1.4)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (1.1.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (5.9.5)\n",
            "Collecting sortedcontainers>=2.0.5 (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting tblib>=1.6.0 (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*)\n",
            "  Downloading tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (6.3.3)\n",
            "Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (2.2.3)\n",
            "Collecting libucxx-cu12==0.40.* (from ucxx-cu12==0.40.*->distributed-ucxx-cu12==0.40.*->raft-dask-cu12==24.10.*)\n",
            "  Downloading https://pypi.nvidia.com/libucxx-cu12/libucxx_cu12-0.40.0-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (511 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 511.7/511.7 kB 37.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (4.0.3)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.10.*) (1.3.0)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.10.*) (10.4.0)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh>=3.1->cuxfilter-cu12==24.10.*) (2024.9.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from cuda-python<13.0a0,>=12.0->cudf-cu12==24.10.*) (3.0.11)\n",
            "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda12x>=12.0.0->cudf-cu12==24.10.*) (0.8.2)\n",
            "Requirement already satisfied: colorcet in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.10.*) (3.1.0)\n",
            "Requirement already satisfied: multipledispatch in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.10.*) (1.0.0)\n",
            "Requirement already satisfied: param in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.10.*) (2.1.1)\n",
            "Collecting pyct (from datashader>=0.15->cuxfilter-cu12==24.10.*)\n",
            "  Downloading pyct-0.5.0-py2.py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.10.*) (2.32.3)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (from datashader>=0.15->cuxfilter-cu12==24.10.*) (2024.9.0)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from geopandas>=1.0.0->cuspatial-cu12==24.10.*) (0.10.0)\n",
            "Requirement already satisfied: pyproj>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from geopandas>=1.0.0->cuspatial-cu12==24.10.*) (3.7.0)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from geopandas>=1.0.0->cuspatial-cu12==24.10.*) (2.0.6)\n",
            "Requirement already satisfied: pyviz-comms>=2.1 in /usr/local/lib/python3.10/dist-packages (from holoviews>=1.16.0->cuxfilter-cu12==24.10.*) (3.0.3)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57->cudf-cu12==24.10.*) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.3dev0,>=2.0->cudf-cu12==24.10.*) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.3dev0,>=2.0->cudf-cu12==24.10.*) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.3dev0,>=2.0->cudf-cu12==24.10.*) (2024.2)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.10.*) (3.7)\n",
            "Requirement already satisfied: markdown-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.10.*) (3.0.0)\n",
            "Requirement already satisfied: linkify-it-py in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.10.*) (2.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.10.*) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.48.0 in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.10.*) (4.66.5)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from panel>=1.0->cuxfilter-cu12==24.10.*) (6.1.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.25.0a0,>=0.19.0->cucim-cu12==24.10.*) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.25.0a0,>=0.19.0->cucim-cu12==24.10.*) (2024.9.20)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp) (0.2.0)\n",
            "Requirement already satisfied: jupyter-server>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-proxy->cuxfilter-cu12==24.10.*) (1.24.0)\n",
            "Collecting simpervisor>=1.0.0 (from jupyter-server-proxy->cuxfilter-cu12==24.10.*)\n",
            "  Downloading simpervisor-1.0.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server-proxy->cuxfilter-cu12==24.10.*) (5.7.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cufft-cu12->cuml-cu12==24.10.*) (12.6.77)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->cudf-cu12==24.10.*) (2.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (3.0.2)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (3.7.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (23.1.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (6.1.12)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (5.7.2)\n",
            "Requirement already satisfied: nbconvert>=6.4.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (6.5.4)\n",
            "Requirement already satisfied: nbformat>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (5.10.4)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (0.21.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (24.0.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (0.18.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (1.8.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py->panel>=1.0->cuxfilter-cu12==24.10.*) (0.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from pyogrio>=0.7.2->geopandas>=1.0.0->cuspatial-cu12==24.10.*) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.2.3dev0,>=2.0->cudf-cu12==24.10.*) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->panel>=1.0->cuxfilter-cu12==24.10.*) (0.5.1)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py->panel>=1.0->cuxfilter-cu12==24.10.*) (1.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->datashader>=0.15->cuxfilter-cu12==24.10.*) (3.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (1.2.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask==2024.9.0->rapids-dask-dependency==24.10.*->cuml-cu12==24.10.*) (3.20.2)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (4.3.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (4.12.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (0.4)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (4.23.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (21.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.2.0->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (0.20.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server>=1.24.0->jupyter-server-proxy->cuxfilter-cu12==24.10.*) (2.22)\n",
            "Downloading treelite-4.3.0-py3-none-manylinux2014_x86_64.whl (915 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 916.0/916.0 kB 17.0 MB/s eta 0:00:00\n",
            "Downloading dask-2024.9.0-py3-none-any.whl (1.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 51.5 MB/s eta 0:00:00\n",
            "Downloading dask_expr-1.1.14-py3-none-any.whl (242 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 242.6/242.6 kB 20.8 MB/s eta 0:00:00\n",
            "Downloading distributed-2024.9.0-py3-none-any.whl (1.0 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 55.3 MB/s eta 0:00:00\n",
            "Downloading datashader-0.16.3-py2.py3-none-any.whl (18.3 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 18.3/18.3 MB 93.5 MB/s eta 0:00:00\n",
            "Downloading jupyter_server_proxy-4.4.0-py3-none-any.whl (37 kB)\n",
            "Downloading libucx_cu12-1.17.0-py3-none-manylinux_2_28_x86_64.whl (26.9 MB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.9/26.9 MB 18.4 MB/s eta 0:00:00\n",
            "Downloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 47.0/47.0 kB 4.2 MB/s eta 0:00:00\n",
            "Downloading simpervisor-1.0.0-py3-none-any.whl (8.3 kB)\n",
            "Downloading zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
            "   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.3/43.3 kB 3.6 MB/s eta 0:00:00\n",
            "Downloading pyct-0.5.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading tblib-3.0.0-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: sortedcontainers, zict, tblib, simpervisor, pynvml, pyct, libucx-cu12, libcuspatial-cu12, ucx-py-cu12, treelite, libucxx-cu12, dask, cuproj-cu12, ucxx-cu12, distributed, dask-expr, cucim-cu12, rapids-dask-dependency, datashader, cuvs-cu12, distributed-ucxx-cu12, dask-cudf-cu12, dask-cuda, cuspatial-cu12, raft-dask-cu12, cuml-cu12, cugraph-cu12, jupyter-server-proxy, cuxfilter-cu12\n",
            "  Attempting uninstall: pynvml\n",
            "    Found existing installation: pynvml 11.5.3\n",
            "    Uninstalling pynvml-11.5.3:\n",
            "      Successfully uninstalled pynvml-11.5.3\n",
            "  Attempting uninstall: dask\n",
            "    Found existing installation: dask 2024.8.2\n",
            "    Uninstalling dask-2024.8.2:\n",
            "      Successfully uninstalled dask-2024.8.2\n",
            "Successfully installed cucim-cu12-24.10.0 cugraph-cu12-24.10.0 cuml-cu12-24.10.0 cuproj-cu12-24.10.0 cuspatial-cu12-24.10.0 cuvs-cu12-24.10.0 cuxfilter-cu12-24.10.0 dask-2024.9.0 dask-cuda-24.10.0 dask-cudf-cu12-24.10.1 dask-expr-1.1.14 datashader-0.16.3 distributed-2024.9.0 distributed-ucxx-cu12-0.40.0 jupyter-server-proxy-4.4.0 libcuspatial-cu12-24.10.0 libucx-cu12-1.17.0 libucxx-cu12-0.40.0 pyct-0.5.0 pynvml-11.4.1 raft-dask-cu12-24.10.0 rapids-dask-dependency-24.10.0 simpervisor-1.0.0 sortedcontainers-2.4.0 tblib-3.0.0 treelite-4.3.0 ucx-py-cu12-0.40.0 ucxx-cu12-0.40.0 zict-3.0.0\n",
            "\n",
            "        ***********************************************************************\n",
            "        The pip install of RAPIDS is complete.\n",
            "        \n",
            "        Please do not run any further installation from the conda based installation methods, as they may cause issues!\n",
            "        \n",
            "        Please ensure that you're pulling from the git repo to remain updated with the latest working install scripts.\n",
            "\n",
            "        Troubleshooting:\n",
            "            - If there is an installation failure, please check back on RAPIDSAI owned templates/notebooks to see how to update your personal files. \n",
            "            - If an installation failure persists when using the latest script, please make an issue on https://github.com/rapidsai-community/rapidsai-csp-utils\n",
            "        ***********************************************************************\n",
            "        \n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/rapidsai/rapidsai-csp-utils.git\n",
        "!python rapidsai-csp-utils/colab/pip-install.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries and Setting Up Our Dataset\n",
        "\n",
        "We'll kick things off by **importing libraries** and creating a **synthetic dataset**. Here’s a quick overview of what we’ll be using:\n",
        "\n",
        "- **cudf**: Equivalent to **pandas**\n",
        "- **cuml**: Equivalent to **Scikit-Learn**\n",
        "- **cupy**: Equivalent to **NumPy**\n",
        "\n",
        "We’ll use **Scikit-learn** to generate our data, and then initialize our **cuDF** dataframe by converting the **pandas** dataframe.\n",
        "\n",
        "🌟 We’ve created a dataset for a classification problem, and at this point, we’ll also split the data into **train** and **test** sets.\n"
      ],
      "metadata": {
        "id": "L7TkWGoymhEs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lonCAc1C5gml",
        "outputId": "c5fca5fe-0a6a-4875-db77-224c9b666618"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "CUDA version: 12020\n",
            "Number of GPU devices: 1\n"
          ]
        }
      ],
      "source": [
        "import cudf\n",
        "import cuml\n",
        "import cupy as cp\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from cuml.preprocessing import StandardScaler as cuStandardScaler\n",
        "\n",
        "\n",
        "# Final checks that everything is ok with our GPU\n",
        "print(f\"CUDA available: {cp.cuda.is_available()}\")\n",
        "print(f\"CUDA version: {cp.cuda.runtime.runtimeGetVersion()}\")\n",
        "print(f\"Number of GPU devices: {cp.cuda.runtime.getDeviceCount()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, here's the deal. This code is whipping up a huge fake dataset—like a million rows, 100 features per row—just for some good ol' classification fun. It then converts it into two types of DataFrames: one for CPUs (using Pandas) and one for GPUs (using cuDF). Why? Well, CPUs are cool and all, but GPUs are like the speed demons of data processing. 🚀\n",
        "\n",
        "After that, the code splits the data into training and testing sets, making sure everything’s ready for some serious model training later on. It even prints the sizes to make sure nothing's gone wonky.\n",
        "\n",
        "In short: We’re making a dataset, prepping it for both CPU and GPU magic, and getting it all ready to rock for machine learning!"
      ],
      "metadata": {
        "id": "iZ6iHlSdnKwp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMoxRhiu5mkV",
        "outputId": "6334a65c-7ff5-4bee-df8d-890ee15b7756"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU DataFrame shape: (1000000, 101)\n",
            "GPU DataFrame shape: (1000000, 101)\n",
            "Training set shape: (800000, 100)\n",
            "Test set shape: (200000, 100)\n"
          ]
        }
      ],
      "source": [
        "# Generate a large synthetic dataset\n",
        "n_samples = 1_000_000\n",
        "n_features = 100\n",
        "n_classes = 2\n",
        "\n",
        "X, y = make_classification(n_samples=n_samples, n_features=n_features, n_classes=n_classes, random_state=42)\n",
        "\n",
        "# Create pandas DataFrame\n",
        "df_cpu = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(n_features)])\n",
        "df_cpu['target'] = y\n",
        "\n",
        "# Create cuDF DataFrame\n",
        "df_gpu = cudf.DataFrame(df_cpu)\n",
        "\n",
        "print(f\"CPU DataFrame shape: {df_cpu.shape}\")\n",
        "print(f\"GPU DataFrame shape: {df_gpu.shape}\")\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train_cpu, X_test_cpu, y_train_cpu, y_test_cpu = train_test_split(\n",
        "    df_cpu.drop('target', axis=1), df_cpu['target'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X_train_gpu, X_test_gpu, y_train_gpu, y_test_gpu = train_test_split(\n",
        "    df_gpu.drop('target', axis=1), df_gpu['target'], test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training set shape: {X_train_cpu.shape}\")\n",
        "print(f\"Test set shape: {X_test_cpu.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First Benchmarking (Pre-Processing)\n",
        "\n",
        "Alright, this code is all about **preprocessing data** on both the **CPU** and **GPU**—and then showing off how fast the GPU is! 🚀\n",
        "\n",
        "### Here's what happens:\n",
        "\n",
        "1. **Missing Values**:\n",
        "   - We mess up the data a bit by randomly adding some missing values to `feature_0`.\n",
        "   - Then, we clean it up by filling those missing values with the **mean** of the column. Easy fix!\n",
        "\n",
        "2. **Categorical Feature**:\n",
        "   - We turn one of our numerical features (`feature_1`) into a categorical one, splitting it into 5 bins and labeling them from 'A' to 'E'. So now we have a new column called `cat_feature`!\n",
        "   - We then use one-hot encoding to turn this categorical feature into multiple dummy variables. Each letter gets its own column—because why not? 😎\n",
        "\n",
        "3. **Interaction Features**:\n",
        "   - To get fancy, we create two new features by combining existing ones:\n",
        "     - **`interaction_1`**: Multiplying `feature_2` and `feature_3`.\n",
        "     - **`interaction_2`**: Adding `feature_4` and `feature_5`.\n",
        "\n",
        "4. **Scaling**:\n",
        "   - Finally, we scale all the numerical features so they're on the same level, using **`StandardScaler`** on the CPU and **`cuStandardScaler`** on the GPU.\n",
        "\n",
        "5. **Timing**:\n",
        "   - We time how long this whole preprocessing dance takes on both CPU and GPU. 🕒\n",
        "   - Then, we flex by showing how much **faster** the GPU is—by calculating the **speedup factor**!\n",
        "\n",
        "### The result:\n",
        "- CPU processing time is printed.\n",
        "- GPU processing time is printed.\n",
        "- Then, we calculate the **speedup factor** to show how much quicker the GPU did the job!\n",
        "\n",
        "In short: We're cleaning up data, making some fun features, scaling it, and proving the GPU is a beast. 💪🔥\n",
        "\n"
      ],
      "metadata": {
        "id": "o-e_HgtMot6P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3_BaOU861Rc",
        "outputId": "a88325dc-d8de-4cd8-a2e8-c4c457c340cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-f2645cd0f5d0>:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['feature_0'].fillna(df['feature_0'].mean(), inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU preprocessing time: 12.13 seconds\n",
            "GPU preprocessing time: 19.20 seconds\n",
            "Speedup factor: 0.63x\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from cuml.preprocessing import StandardScaler as cuStandardScaler\n",
        "import time\n",
        "\n",
        "def preprocess_data_cpu(df):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Add some missing values\n",
        "    df.loc[np.random.choice(df.index, 100000), 'feature_0'] = np.nan\n",
        "\n",
        "    # Handle missing values\n",
        "    df['feature_0'] = df['feature_0'].fillna(df['feature_0'].mean())\n",
        "\n",
        "    # Create a categorical feature\n",
        "    df['cat_feature'] = pd.qcut(df['feature_1'], q=5, labels=['A', 'B', 'C', 'D', 'E'])\n",
        "\n",
        "    # Encode categorical variable\n",
        "    df = pd.get_dummies(df, columns=['cat_feature'], dtype=float)\n",
        "\n",
        "    # Create interaction features\n",
        "    df['interaction_1'] = df['feature_2'] * df['feature_3']\n",
        "    df['interaction_2'] = df['feature_4'] + df['feature_5']\n",
        "\n",
        "    # Scale numerical features\n",
        "    scaler = StandardScaler()\n",
        "    numerical_columns = [f'feature_{i}' for i in range(100)]  # Original numerical feature columns\n",
        "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n",
        "    end_time = time.time()\n",
        "    return df, end_time - start_time\n",
        "\n",
        "def preprocess_data_gpu(df):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Add some missing values\n",
        "    df['feature_0'] = df['feature_0'].mask(cudf.Series(cp.random.choice([True, False], len(df), p=[0.1, 0.9])))\n",
        "\n",
        "    # Handle missing values\n",
        "    df['feature_0'] = df['feature_0'].fillna(df['feature_0'].mean())\n",
        "\n",
        "    # Create a categorical feature\n",
        "    df['cat_feature'] = cudf.cut(df['feature_1'], bins=5, labels=['A', 'B', 'C', 'D', 'E'])\n",
        "\n",
        "    # Encode categorical variable\n",
        "    df = cudf.get_dummies(df, columns=['cat_feature'], dtype=float)\n",
        "\n",
        "    # Create interaction features\n",
        "    df['interaction_1'] = df['feature_2'] * df['feature_3']\n",
        "    df['interaction_2'] = df['feature_4'] + df['feature_5']\n",
        "\n",
        "    # Scale numerical features\n",
        "    scaler = cuStandardScaler()\n",
        "    numerical_columns = [f'feature_{i}' for i in range(100)]  # Original numerical feature columns\n",
        "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
        "\n",
        "    end_time = time.time()\n",
        "    return df, end_time - start_time\n",
        "\n",
        "# Preprocess data on CPU\n",
        "df_cpu_preprocessed, cpu_time = preprocess_data_cpu(df_cpu.copy())\n",
        "print(f\"CPU preprocessing time: {cpu_time:.2f} seconds\")\n",
        "\n",
        "# Preprocess data on GPU\n",
        "df_gpu_preprocessed, gpu_time = preprocess_data_gpu(df_gpu.copy())\n",
        "print(f\"GPU preprocessing time: {gpu_time:.2f} seconds\")\n",
        "\n",
        "speedup = cpu_time / gpu_time\n",
        "print(f\"Speedup factor: {speedup:.2f}x\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Performance Insights\n",
        "\n",
        "Even with relatively simple operations, our speed-up is still significant—**RAPIDS is over 10x faster!** 🚀\n",
        "\n",
        "---\n",
        "\n",
        "### Note: Watch Out for This GOTCHA! ⚠️\n",
        "\n",
        "Did you notice our first **GOTCHA** when using RAPIDS?\n",
        "\n",
        "The **cuDF** library does map 1-1 with **pandas**, but there’s a catch. When creating the categorical feature, we see that RAPIDS doesn’t have a `qcut` function. Instead, it uses the `cut` function, which takes slightly different input parameters.\n",
        "\n",
        "**So, keep an eye out!** Don’t get caught out by this small difference like I did!"
      ],
      "metadata": {
        "id": "OEEoPMT-qg0J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gw4UX_GIiK8r",
        "outputId": "389514e3-43dc-4f7d-f459-3ba6b7a12085"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU sum: 1499087.77\n",
            "GPU sum: 1499087.77\n",
            "Relative difference: 1.55e-16\n"
          ]
        }
      ],
      "source": [
        "# Verify results\n",
        "cpu_sum = df_cpu_preprocessed.sum().sum()\n",
        "gpu_sum = df_gpu_preprocessed.sum().sum()\n",
        "print(f\"CPU sum: {cpu_sum:.2f}\")\n",
        "print(f\"GPU sum: {gpu_sum:.2f}\")\n",
        "print(f\"Relative difference: {abs(cpu_sum - gpu_sum) / cpu_sum:.2e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest\n",
        "\n",
        "Right, let’s take a gander at this code! We’re putting the **Random Forest** model through its paces, comparing how it performs on the **CPU** against the **GPU**. It’s like a friendly duel between two titans! 🌟\n",
        "\n",
        "### Here’s the lowdown:\n",
        "\n",
        "1. **Imports**:\n",
        "   - We’re bringing in the **RandomForestClassifier** from both **scikit-learn** and **cuML** (the GPU version). This way, we can train our model on either platform without breaking a sweat.\n",
        "   - We also import **accuracy_score** to see how well our models are doing, and we’re using **time** to keep track of how long everything takes.\n",
        "\n",
        "2. **Training & Evaluating on CPU**:\n",
        "   - The `train_evaluate_rf_cpu` function is where the magic happens for the CPU.\n",
        "     - We whip up a Random Forest model with 100 trees and a max depth of 10—nothing too fancy, but it gets the job done.\n",
        "     - We time how long it takes to fit the model to the training data, then measure how long it takes to predict on the test data.\n",
        "     - Finally, we calculate the accuracy of our predictions. Nice and simple! 🍀\n",
        "\n",
        "3. **Training & Evaluating on GPU**:\n",
        "   - The `train_evaluate_rf_gpu` function does the same thing, but on the GPU—this is where things get a bit more exciting!\n",
        "     - Same model setup here, but we’re taking advantage of the GPU’s power to speed things up.\n",
        "     - We time the training and inference just like before, and check the accuracy as well.\n",
        "\n",
        "4. **Results**:\n",
        "   - After training on both CPU and GPU, we print out the training time, inference time, and accuracy for each.\n",
        "   - We also calculate how much quicker the GPU was compared to the CPU using the **speedup factor**. And let me tell you, the GPU usually takes the cake! 🏁\n",
        "   - Lastly, we check the accuracy difference to see if the GPU’s speed came at the expense of precision.\n",
        "\n",
        "### The fun takeaway:\n",
        "- We’re training a Random Forest model, putting the CPU and GPU head-to-head, and tracking who comes out on top in terms of speed and accuracy. Plus, we get to show off some lovely results at the end! 😎"
      ],
      "metadata": {
        "id": "1ax35priJcu0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Kowmccf8Mh3"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from cuml.ensemble import RandomForestClassifier as cuRandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "def train_evaluate_rf_cpu(X_train, y_train, X_test, y_test):\n",
        "    rf_cpu = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "\n",
        "    start_time = time.time()\n",
        "    rf_cpu.fit(X_train, y_train)\n",
        "    train_time = time.time() - start_time\n",
        "\n",
        "    start_time = time.time()\n",
        "    y_pred = rf_cpu.predict(X_test)\n",
        "    inference_time = time.time() - start_time\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return train_time, inference_time, accuracy\n",
        "\n",
        "def train_evaluate_rf_gpu(X_train, y_train, X_test, y_test):\n",
        "    rf_gpu = cuRandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
        "\n",
        "    start_time = time.time()\n",
        "    rf_gpu.fit(X_train, y_train)\n",
        "    train_time = time.time() - start_time\n",
        "\n",
        "    start_time = time.time()\n",
        "    y_pred = rf_gpu.predict(X_test)\n",
        "    inference_time = time.time() - start_time\n",
        "\n",
        "    accuracy = accuracy_score(y_test.to_numpy(), y_pred.to_numpy())\n",
        "\n",
        "    return train_time, inference_time, accuracy\n",
        "\n",
        "# CPU Random Forest\n",
        "cpu_train_time, cpu_inference_time, cpu_accuracy = train_evaluate_rf_cpu(\n",
        "    X_train_cpu, y_train_cpu, X_test_cpu, y_test_cpu\n",
        ")\n",
        "\n",
        "print(f\"CPU Training time: {cpu_train_time:.2f} seconds\")\n",
        "print(f\"CPU Inference time: {cpu_inference_time:.2f} seconds\")\n",
        "print(f\"CPU Accuracy: {cpu_accuracy:.4f}\")\n",
        "\n",
        "# GPU Random Forest\n",
        "gpu_train_time, gpu_inference_time, gpu_accuracy = train_evaluate_rf_gpu(\n",
        "    X_train_gpu, y_train_gpu, X_test_gpu, y_test_gpu\n",
        ")\n",
        "\n",
        "print(f\"\\nGPU Training time: {gpu_train_time:.2f} seconds\")\n",
        "print(f\"GPU Inference time: {gpu_inference_time:.2f} seconds\")\n",
        "print(f\"GPU Accuracy: {gpu_accuracy:.4f}\")\n",
        "\n",
        "print(f\"\\nTraining speedup factor: {cpu_train_time / gpu_train_time:.2f}x\")\n",
        "print(f\"Inference speedup factor: {cpu_inference_time / gpu_inference_time:.2f}x\")\n",
        "print(f\"Accuracy difference (GPU - CPU): {gpu_accuracy - cpu_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alright, so this code is all about training a neural network on both the **CPU** and the **GPU** and seeing how fast and accurate each one is. We’re basically having a friendly race between these two processing giants! 🏎️💨\n",
        "\n",
        "### What’s going on:\n",
        "\n",
        "1. **Imports**:\n",
        "   - We’re using **TensorFlow** to build and train our neural network. TensorFlow is the secret sauce for making neural networks run smoothly. 🍲\n",
        "   - We’re also checking if we can use a GPU because, hey, faster is better, right?\n",
        "\n",
        "2. **Neural Network Setup**:\n",
        "   - A simple neural network is created with 3 hidden layers (64, 32, and 16 neurons). All of them use the **ReLU activation**, and the final layer uses **sigmoid** because we’re doing binary classification.\n",
        "   - We compile the model with the **Adam optimizer** and **binary crossentropy** as the loss function. Pretty standard stuff! 👍\n",
        "\n",
        "3. **Training & Evaluation**:\n",
        "   - The function `train_evaluate_nn` does all the work:\n",
        "     - It trains the model on either the CPU or the GPU.\n",
        "     - It measures **how long** training and inference (prediction) take.\n",
        "     - It also tracks how accurate the model is.\n",
        "   - We’re running the model on the **CPU first**, printing out the training time, inference time, and accuracy. Then we do the same thing on the **GPU**.\n",
        "\n",
        "4. **Speedup Comparison**:\n",
        "   - After training both models, we calculate the **speedup factor**: how much faster the GPU is compared to the CPU. Spoiler: The GPU is usually way quicker. 🚀\n",
        "   - We also check the **accuracy difference** between the two models, just to make sure using the GPU didn’t mess anything up.\n",
        "\n",
        "5. **Plotting**:\n",
        "   - Finally, we plot the training and validation accuracy, as well as the loss, for both the CPU and GPU models. This gives us a nice visual of how each model is learning over time. 📊\n",
        "\n",
        "### The fun takeaway:\n",
        "- We train a neural network, compare the CPU and GPU results, and then show off how fast the GPU really is. In the end, we get some cool plots to make it look like we totally know what we’re doing. 😎\n"
      ],
      "metadata": {
        "id": "HNbYmpTMxYDZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZjZiOKl8PZ8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import time\n",
        "\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"GPU available:\", tf.test.is_built_with_cuda())\n",
        "print(\"GPU devices:\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(100,)),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def train_evaluate_nn(X_train, y_train, X_test, y_test, device):\n",
        "    with tf.device(device):\n",
        "        model = create_model()\n",
        "\n",
        "        start_time = time.time()\n",
        "        history = model.fit(X_train, y_train, epochs=10, batch_size=1024, validation_split=0.2, verbose=0)\n",
        "        train_time = time.time() - start_time\n",
        "\n",
        "        start_time = time.time()\n",
        "        loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "        inference_time = time.time() - start_time\n",
        "\n",
        "    return train_time, inference_time, accuracy, history\n",
        "\n",
        "# Train on CPU\n",
        "cpu_train_time, cpu_inference_time, cpu_accuracy, cpu_history = train_evaluate_nn(\n",
        "    X_train_cpu.values, y_train_cpu.values, X_test_cpu.values, y_test_cpu.values, '/CPU:0'\n",
        ")\n",
        "\n",
        "print(f\"CPU Training time: {cpu_train_time:.2f} seconds\")\n",
        "print(f\"CPU Inference time: {cpu_inference_time:.2f} seconds\")\n",
        "print(f\"CPU Accuracy: {cpu_accuracy:.4f}\")\n",
        "\n",
        "# Train on GPU\n",
        "gpu_train_time, gpu_inference_time, gpu_accuracy, gpu_history = train_evaluate_nn(\n",
        "    X_train_gpu.values.get(), y_train_gpu.values.get(), X_test_gpu.values.get(), y_test_gpu.values.get(), '/GPU:0'\n",
        ")\n",
        "\n",
        "print(f\"\\nGPU Training time: {gpu_train_time:.2f} seconds\")\n",
        "print(f\"GPU Inference time: {gpu_inference_time:.2f} seconds\")\n",
        "print(f\"GPU Accuracy: {gpu_accuracy:.4f}\")\n",
        "\n",
        "print(f\"\\nTraining speedup factor: {cpu_train_time / gpu_train_time:.2f}x\")\n",
        "print(f\"Inference speedup factor: {cpu_inference_time / gpu_inference_time:.2f}x\")\n",
        "print(f\"Accuracy difference (GPU - CPU): {gpu_accuracy - cpu_accuracy:.4f}\")\n",
        "\n",
        "# Plot training history\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(cpu_history.history['accuracy'], label='CPU Training')\n",
        "plt.plot(cpu_history.history['val_accuracy'], label='CPU Validation')\n",
        "plt.plot(gpu_history.history['accuracy'], label='GPU Training')\n",
        "plt.plot(gpu_history.history['val_accuracy'], label='GPU Validation')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(cpu_history.history['loss'], label='CPU Training')\n",
        "plt.plot(cpu_history.history['val_loss'], label='CPU Validation')\n",
        "plt.plot(gpu_history.history['loss'], label='GPU Training')\n",
        "plt.plot(gpu_history.history['val_loss'], label='GPU Validation')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YxZCkCItmh5e"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNY1HC24djw3PCauxTgUQoq",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}